# 强化学习-实战中学习

强化学习通常建模为马尔可夫决策过程（Markov Decision Process, MDP）：

```math
MDP = (S,A,P,R,\gamma)
```
$S$：状态空间

$A$：动作空间


$P(s′∣s,a)$：状态转移概率

$R(s,a)$：即时奖励

$\gamma$：折扣因子



| 术语                    | 说明                                                                                 |              
| --------------------- | ---------------------------------------------------------------------------------- | 
| Agent（智能体）            | 执行动作、与环境交互并学习的决策者                                                                  |              
| Environment（环境）       | 智能体所处的外部世界                                                                         |              
| State $s$             | 环境在某一时刻的描述                                                                         |              
| Action $a$            | 智能体可执行的动作                                                                          |              
| Reward $r$            | 环境对智能体动作的反馈                                                                        |              
| Policy $\pi(a)$         |          给定状态下采取动作的策略                                                                    | 
| Value Function $V(s)$ | 状态的期望回报                                                                            |              
| Q Function $Q(s, a)$  | 状态-动作对的期望回报                                                                        |              
| Return $G_t$          | 从时间步 t 开始累积的回报，通常定义为 $G_t = \sum_{k=0}^{\infty} \gamma^k r_{t+k+1}$，$\gamma$ 为折扣因子 |              
