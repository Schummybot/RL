{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483e14ed-b1a5-47d9-8b52-62efbf2ce294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09e67380-d238-43a0-840e-7737a5dd0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeMC:\n",
    "    def __init__(self, player='X'):\n",
    "        self.player = player\n",
    "        self.states = defaultdict(float)  # state-action value table\n",
    "        self.returns = defaultdict(list)  # to store returns for averaging\n",
    "        self.gamma = 1.0  # discount factor\n",
    "        self.epsilon = 0.5  # exploration rate, can decay over time\n",
    "\n",
    "    def reset_board(self):\n",
    "        return np.zeros((3, 3), dtype=str)\n",
    "    \n",
    "    def get_available_actions(self, board):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if board[i, j] == '']\n",
    "    \n",
    "    def is_winner(self, board, player):\n",
    "        for i in range(3):\n",
    "            if np.all(board[i, :] == player) or np.all(board[:, i] == player):\n",
    "                return True\n",
    "        if board[0, 0] == board[1, 1] == board[2, 2] == player or \\\n",
    "           board[0, 2] == board[1, 1] == board[2, 0] == player:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_draw(self, board):\n",
    "        return '' not in board\n",
    "\n",
    "    def update_board(self, board, action, player):\n",
    "        new_board = board.copy()\n",
    "        new_board[action] = player\n",
    "        return new_board\n",
    "        \n",
    "    def display_board(self, board):\n",
    "        print(\"\\n\".join([\" \".join([cell if cell != '' else '.' for cell in row]) for row in board]))\n",
    "    \n",
    "    \n",
    "    def get_state_key(self, board):\n",
    "        # Convert each row to a tuple and then the whole board to a tuple of tuples\n",
    "        return tuple(tuple(row) for row in board)\n",
    "\n",
    "    def choose_action(self, board):\n",
    "        actions = self.get_available_actions(board)\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(actions)\n",
    "        else:\n",
    "            # Pick the action with the highest estimated reward\n",
    "            state_key = self.get_state_key(board)\n",
    "            q_values = {action: self.states[(state_key, action)] for action in actions}\n",
    "            return max(q_values, key=q_values.get, default=random.choice(actions))\n",
    "\n",
    "    def generate_episode(self):\n",
    "        board = self.reset_board()\n",
    "        episode = []\n",
    "        current_player = self.player\n",
    "        while True:\n",
    "            action = self.choose_action(board)\n",
    "            episode.append((self.get_state_key(board), action, current_player))\n",
    "            board = self.update_board(board, action, current_player)\n",
    "            if self.is_winner(board, current_player):\n",
    "                return episode, 1, current_player  # Win reward\n",
    "            elif self.is_draw(board):\n",
    "                return episode, 0, None  # Draw reward\n",
    "            current_player = 'O' if current_player == 'X' else 'X'\n",
    "\n",
    "    def update_policy(self, episode, reward, winner):\n",
    "        # Using first-visit Monte Carlo control\n",
    "        G = reward  # Reward for terminal state\n",
    "        for i, (state_key, action, player) in enumerate(episode):\n",
    "            if (state_key, action) not in episode[:i]:  # Check first visit\n",
    "                k = 1 if winner == player else -1\n",
    "                self.returns[(state_key, action)].append(G*k)\n",
    "                self.states[(state_key, action)] = np.mean(self.returns[(state_key, action)])\n",
    "\n",
    "    def train(self, episodes=10000, decay_rate=1):\n",
    "        for episode_num in range(episodes):\n",
    "            episode, reward, winner = self.generate_episode()\n",
    "            self.update_policy(episode, reward, winner)\n",
    "            # Decay epsilon to reduce exploration over time\n",
    "            self.epsilon *= decay_rate\n",
    "            \n",
    "            # Optionally, print progress every 1000 episodes\n",
    "            if episode_num % 1000 == 0:\n",
    "                print(episode_num)\n",
    "                for i in range(3):\n",
    "                    for j in range(3):\n",
    "                        print((i,j),agent.states[(agent.get_state_key(np.zeros((3,3),dtype=str)),(i,j))])\n",
    "\n",
    "    def get_best_policy(self, board):\n",
    "        actions = self.get_available_actions(board)\n",
    "        state_key = self.get_state_key(board)\n",
    "        q_values = {action: self.states[(state_key, action)] for action in actions}\n",
    "        best_action = max(q_values, key=q_values.get, default=None)\n",
    "        return best_action\n",
    "        \n",
    "    def play(self):\n",
    "        board = self.reset_board()\n",
    "        current_player = 'X'\n",
    "        \n",
    "        while True:\n",
    "            self.display_board(board)\n",
    "            if current_player == 'X':\n",
    "                action = self.get_best_policy(board)\n",
    "                if action is None:\n",
    "                    print(\"No valid action found. Game over.\")\n",
    "                    break\n",
    "                print(f\"Agent 'X' chooses {action}\")\n",
    "            else:\n",
    "                action = tuple(map(int, input(\"Enter your move (row col): \").split()))\n",
    "            \n",
    "            board = self.update_board(board, action, current_player)\n",
    "            if self.is_winner(board, current_player):\n",
    "                self.display_board(board)\n",
    "                print(f\"Player '{current_player}' wins!\")\n",
    "                break\n",
    "            elif self.is_draw(board):\n",
    "                self.display_board(board)\n",
    "                print(\"It's a draw!\")\n",
    "                break\n",
    "            \n",
    "            current_player = 'O' if current_player == 'X' else 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eba56c6-55f0-4e48-baed-4f20f2465321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using the trained agent\n",
    "agent = TicTacToeMC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80171bdd-f375-421a-82cc-b34149e0995c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(0, 0) 1.0\n",
      "(0, 1) 0.0\n",
      "(0, 2) 0.0\n",
      "(1, 0) 0.0\n",
      "(1, 1) 0.0\n",
      "(1, 2) 0.0\n",
      "(2, 0) 0.0\n",
      "(2, 1) 0.0\n",
      "(2, 2) 0.0\n",
      "1000\n",
      "(0, 0) 0.3212996389891697\n",
      "(0, 1) -0.14545454545454545\n",
      "(0, 2) 0.30985915492957744\n",
      "(1, 0) 0.23469387755102042\n",
      "(1, 1) 0.23809523809523808\n",
      "(1, 2) 0.1276595744680851\n",
      "(2, 0) 0.15873015873015872\n",
      "(2, 1) 0.29850746268656714\n",
      "(2, 2) 0.3\n",
      "2000\n",
      "(0, 0) 0.26737967914438504\n",
      "(0, 1) 0.018018018018018018\n",
      "(0, 2) 0.24113475177304963\n",
      "(1, 0) 0.24358974358974358\n",
      "(1, 1) 0.31176470588235294\n",
      "(1, 2) 0.08163265306122448\n",
      "(2, 0) 0.17543859649122806\n",
      "(2, 1) 0.2047244094488189\n",
      "(2, 2) 0.25595238095238093\n",
      "3000\n",
      "(0, 0) 0.2493857493857494\n",
      "(0, 1) 0.08588957055214724\n",
      "(0, 2) 0.211340206185567\n",
      "(1, 0) 0.2315270935960591\n",
      "(1, 1) 0.34630872483221475\n",
      "(1, 2) 0.026143790849673203\n",
      "(2, 0) 0.17105263157894737\n",
      "(2, 1) 0.13690476190476192\n",
      "(2, 2) 0.2371638141809291\n",
      "4000\n",
      "(0, 0) 0.2502818489289741\n",
      "(0, 1) 0.06944444444444445\n",
      "(0, 2) 0.2190082644628099\n",
      "(1, 0) 0.1732283464566929\n",
      "(1, 1) 0.3756777691711851\n",
      "(1, 2) 0.05714285714285714\n",
      "(2, 0) 0.2175925925925926\n",
      "(2, 1) 0.07488986784140969\n",
      "(2, 2) 0.24017467248908297\n",
      "5000\n",
      "(0, 0) 0.24\n",
      "(0, 1) 0.041666666666666664\n",
      "(0, 2) 0.23529411764705882\n",
      "(1, 0) 0.18971061093247588\n",
      "(1, 1) 0.3826558265582656\n",
      "(1, 2) 0.072992700729927\n",
      "(2, 0) 0.24632352941176472\n",
      "(2, 1) 0.0313588850174216\n",
      "(2, 2) 0.2220039292730845\n",
      "6000\n",
      "(0, 0) 0.23618090452261306\n",
      "(0, 1) 0.05572755417956656\n",
      "(0, 2) 0.2638888888888889\n",
      "(1, 0) 0.14754098360655737\n",
      "(1, 1) 0.4049207673060884\n",
      "(1, 2) 0.10122699386503067\n",
      "(2, 0) 0.23384615384615384\n",
      "(2, 1) 0.04310344827586207\n",
      "(2, 2) 0.18214285714285713\n",
      "7000\n",
      "(0, 0) 0.23120837297811608\n",
      "(0, 1) 0.09947643979057591\n",
      "(0, 2) 0.2647058823529412\n",
      "(1, 0) 0.16267942583732056\n",
      "(1, 1) 0.40861662739818244\n",
      "(1, 2) 0.06824146981627296\n",
      "(2, 0) 0.22279792746113988\n",
      "(2, 1) 0.0475\n",
      "(2, 2) 0.17052980132450332\n",
      "8000\n",
      "(0, 0) 0.22752293577981653\n",
      "(0, 1) 0.08823529411764706\n",
      "(0, 2) 0.2688888888888889\n",
      "(1, 0) 0.1777301927194861\n",
      "(1, 1) 0.40933521923620936\n",
      "(1, 2) 0.10738255033557047\n",
      "(2, 0) 0.24311926605504589\n",
      "(2, 1) 0.037037037037037035\n",
      "(2, 2) 0.16296296296296298\n",
      "9000\n",
      "(0, 0) 0.226447709593777\n",
      "(0, 1) 0.08032128514056225\n",
      "(0, 2) 0.26095617529880477\n",
      "(1, 0) 0.1776061776061776\n",
      "(1, 1) 0.41254612546125463\n",
      "(1, 2) 0.1007905138339921\n",
      "(2, 0) 0.22376237623762377\n",
      "(2, 1) 0.041015625\n",
      "(2, 2) 0.17615176151761516\n"
     ]
    }
   ],
   "source": [
    "agent.train(episodes=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac1845e9-cd0f-47c3-80e3-187b89da70c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "Agent 'X' chooses (1, 1)\n",
      ". . .\n",
      ". X .\n",
      ". . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (row col):  0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O . .\n",
      ". X .\n",
      ". . .\n",
      "Agent 'X' chooses (0, 1)\n",
      "O X .\n",
      ". X .\n",
      ". . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (row col):  2 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O X .\n",
      ". X .\n",
      ". O .\n",
      "Agent 'X' chooses (1, 0)\n",
      "O X .\n",
      "X X .\n",
      ". O .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (row col):  1 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O X .\n",
      "X X O\n",
      ". O .\n",
      "Agent 'X' chooses (0, 2)\n",
      "O X X\n",
      "X X O\n",
      ". O .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (row col):  2 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O X X\n",
      "X X O\n",
      "O O .\n",
      "Agent 'X' chooses (2, 2)\n",
      "O X X\n",
      "X X O\n",
      "O O X\n",
      "It's a draw!\n"
     ]
    }
   ],
   "source": [
    "agent.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e4957-2dd2-4458-b221-1f3083f73a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xu",
   "language": "python",
   "name": "xu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
